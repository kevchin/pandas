{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad84510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://developers.google.com/drive/api/v3/ref-search-terms\n",
    "# https://developers.google.com/drive/api/v3/search-files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf28ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os.path\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from googleapiclient import discovery\n",
    "from googleapiclient.errors import HttpError\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# NLP libraries for keywords and summaries\n",
    "import re\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "#import heapq\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816b4922",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCOPES = ['https://www.googleapis.com/auth/documents.readonly', \n",
    "          'https://www.googleapis.com/auth/documents',\n",
    "          'https://www.googleapis.com/auth/drive.metadata.readonly',\n",
    "          'https://www.googleapis.com/auth/drive',\n",
    "          'https://www.googleapis.com/auth/drive.file',\n",
    "          'https://www.googleapis.com/auth/drive.readonly'\n",
    "         ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8faf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCreds(scopes):\n",
    "    creds = None\n",
    "    # The file token.json stores the user's access and refresh tokens, and is\n",
    "    # created automatically when the authorization flow completes for the first\n",
    "    # time.\n",
    "    if os.path.exists('token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('token.json', scopes)\n",
    "    # If there are no (valid) credentials available, let the user log in.\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'credentials.json', scopes)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        # Save the credentials for the next run\n",
    "        with open('token.json', 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "    return(creds)\n",
    "\n",
    "def searchGDrive(query, creds, debug=False):\n",
    "    DRIVE = discovery.build('drive', 'v3', credentials=creds)\n",
    "    retError = \"\"\n",
    "    errorState = False\n",
    "    try:\n",
    "        fileList = DRIVE.files().list(q=query).execute()\n",
    "    except HttpError as ex:\n",
    "        errorState = True\n",
    "        template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "        message = template.format(type(ex).__name__, ex.args)\n",
    "        if (debug):\n",
    "            print (message)\n",
    "        retError = str(ex.resp.status)\n",
    "        if ex.resp.get('content-type', '').startswith('application/json'):\n",
    "            reason = json.loads(ex.content).get('error').get('errors')[0].get('reason')\n",
    "            saveString = json.loads(ex.content)\n",
    "            if (debug):\n",
    "                print (ex.resp.status, reason)\n",
    "            retError = str(ex.resp.status) + ' - ' + reason\n",
    "    \n",
    "    if (errorState or (not(fileList and 'files' in fileList))):\n",
    "        if (debug):\n",
    "            print ('Error')\n",
    "        return(False, pd.DataFrame(), retError)\n",
    "\n",
    "    files_df = pd.DataFrame(pd.json_normalize(fileList))\n",
    "    fileCount = len(files_df.index)\n",
    "    if (len(files_df.index) == 0):\n",
    "        return (False, files_df, 'Nothing Found')\n",
    "    return (True, files_df, '')\n",
    "\n",
    "def getDocumentFromID(docID, creds, debug=False):\n",
    "    service = build('docs', 'v1', credentials=creds)\n",
    "\n",
    "    retError = \"\"\n",
    "    errorState = False\n",
    "    try:\n",
    "        document = service.documents().get(documentId=docID).execute()\n",
    "    except HttpError as ex:\n",
    "        errorState = True\n",
    "        template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "        message = template.format(type(ex).__name__, ex.args)\n",
    "        if (debug):\n",
    "            print (message)\n",
    "        retError = str(ex.resp.status)\n",
    "        if ex.resp.get('content-type', '').startswith('application/json'):\n",
    "            reason = json.loads(ex.content).get('error').get('errors')[0].get('reason')\n",
    "            saveString = json.loads(ex.content)\n",
    "            if (debug):\n",
    "                print (ex.resp.status, reason)\n",
    "            retError = str(ex.resp.status) + ' - ' + reason\n",
    "    \n",
    "    if (errorState or (not(document))):\n",
    "        if (debug):\n",
    "            print ('Error')\n",
    "        return(False, {}, retError)\n",
    "    \n",
    "    return(True, document, retError)\n",
    "\n",
    "\n",
    "def googleDriveInfo(fileID, creds, debug=False):\n",
    "    DRIVE = discovery.build('drive', 'v3', credentials=creds)\n",
    "\n",
    "    # Drive V3 API:\n",
    "    #\n",
    "    #try:\n",
    "    saveString = \"\"\n",
    "    retError = \"\"\n",
    "    errorState = False\n",
    "    try:\n",
    "        cols = 'name,mimeType,owners,createdTime,modifiedTime,shared,permissions'\n",
    "        fileInfo = DRIVE.files().get(fileId=fileID,fields=cols).execute()\n",
    "    except HttpError as ex:\n",
    "        errorState = True\n",
    "        template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "        message = template.format(type(ex).__name__, ex.args)\n",
    "        if (debug):\n",
    "            print (message)\n",
    "        retError = str(ex.resp.status)\n",
    "        if ex.resp.get('content-type', '').startswith('application/json'):\n",
    "            reason = json.loads(ex.content).get('error').get('errors')[0].get('reason')\n",
    "            saveString = json.loads(ex.content)\n",
    "            if (debug):\n",
    "                print (ex.resp.status, reason)\n",
    "            retError = str(ex.resp.status) + ' - ' + reason\n",
    "        \n",
    "    if (errorState or not(fileInfo)):\n",
    "        return(False, retError)\n",
    "    \n",
    "    return (True, fileInfo)\n",
    "\n",
    "def googleDriveText(fileID, creds, debug=False):\n",
    "    DRIVE = discovery.build('drive', 'v3', credentials=creds)\n",
    "    retError = \"\"\n",
    "    errorState = False\n",
    "    try:\n",
    "        fileText = DRIVE.files().export(fileId=fileID, mimeType='text/plain').execute()\n",
    "    except HttpError as ex:\n",
    "        errorState = True\n",
    "        template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "        message = template.format(type(ex).__name__, ex.args)\n",
    "        if (debug):\n",
    "            print (message)\n",
    "        retError = str(ex.resp.status)\n",
    "        if ex.resp.get('content-type', '').startswith('application/json'):\n",
    "            reason = json.loads(ex.content).get('error').get('errors')[0].get('reason')\n",
    "            saveString = json.loads(ex.content)\n",
    "            if (debug):\n",
    "                print (ex.resp.status, reason)\n",
    "            retError = str(ex.resp.status) + ' - ' + reason\n",
    "    \n",
    "    if errorState:\n",
    "        if (debug):\n",
    "            print ('Error')\n",
    "        return(False, retError)\n",
    "    else:\n",
    "        if (debug):\n",
    "            print (len(fileText.decode('utf-8')))\n",
    "        return(True, fileText.decode('utf-8'))\n",
    "\n",
    "def getSummary(document, keywordCount = 5, debug=False):\n",
    "    # Removing Square Brackets and Extra Spaces\n",
    "    article_text = re.sub(r'\\[[0-9]*\\]', ' ', document)\n",
    "    article_text = re.sub(r'\\s+', ' ', article_text)\n",
    "    # Removing special characters and digits\n",
    "    formatted_article_text = re.sub('[^a-zA-Z]', ' ', article_text )\n",
    "    formatted_article_text = re.sub(r'\\s+', ' ', formatted_article_text)\n",
    "    sentence_list = nltk.sent_tokenize(article_text)\n",
    "    stopwords = list(ENGLISH_STOP_WORDS)\n",
    "    \n",
    "    word_frequencies = {}\n",
    "    for word in nltk.word_tokenize(formatted_article_text):\n",
    "        if word not in stopwords:\n",
    "            if word not in word_frequencies.keys():\n",
    "                word_frequencies[word] = 1\n",
    "            else:\n",
    "                word_frequencies[word] += 1\n",
    "        maximum_frequncy = 0\n",
    "        if len(word_frequencies) > 0:\n",
    "            maximum_frequncy = max(word_frequencies.values())\n",
    "        else:\n",
    "            return('', '')\n",
    "    for word in word_frequencies.keys():\n",
    "        word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)\n",
    "        sentence_scores = {}\n",
    "    for sent in sentence_list:\n",
    "        for word in nltk.word_tokenize(sent.lower()):\n",
    "            if word in word_frequencies.keys():\n",
    "                if len(sent.split(' ')) < 30:\n",
    "                    if sent not in sentence_scores.keys():\n",
    "                        sentence_scores[sent] = word_frequencies[word]\n",
    "                    else:\n",
    "                        sentence_scores[sent] += word_frequencies[word]\n",
    "                        \n",
    "    wordslist = nltk.word_tokenize(formatted_article_text)\n",
    "    filtered_words = [words for words in wordslist if words.lower() not in stopwords]\n",
    "\n",
    "    fdist = FreqDist(filtered_words)\n",
    "    frequent_words = [[fdist[word], word] for word in set(filtered_words) if len(word) > 2 and fdist[word] >= 2]\n",
    "\n",
    "    #\n",
    "    # Record the frequency count of\n",
    "    #\n",
    "    sorted_word_frequencies = {}\n",
    "    for item in sorted(frequent_words):\n",
    "        sorted_word_frequencies[item[1]] = item[0]\n",
    "    \n",
    "    interestingKeywords = list(sorted_word_frequencies.keys())[-keywordCount:]\n",
    "        \n",
    "    #summary_sentences = heapq.nlargest(3, sentence_scores, key=sentence_scores.get)\n",
    "    #summary = ' '.join(summary_sentences)\n",
    "    return (interestingKeywords, '' )\n",
    "\n",
    "\n",
    "def getCommentInfo(fileID, creds, debug=False):\n",
    "    DRIVE = discovery.build('drive', 'v3', credentials=creds)\n",
    "    retError = \"\"\n",
    "    errorState = False\n",
    "    try:\n",
    "        commentList = DRIVE.comments().list(fileId=fileID, fields='comments').execute()\n",
    "    except HttpError as ex:\n",
    "        errorState = True\n",
    "        template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "        message = template.format(type(ex).__name__, ex.args)\n",
    "        if (debug):\n",
    "            print (message)\n",
    "        retError = str(ex.resp.status)\n",
    "        if ex.resp.get('content-type', '').startswith('application/json'):\n",
    "            reason = json.loads(ex.content).get('error').get('errors')[0].get('reason')\n",
    "            saveString = json.loads(ex.content)\n",
    "            if (debug):\n",
    "                print (ex.resp.status, reason)\n",
    "            retError = str(ex.resp.status) + ' - ' + reason\n",
    "    \n",
    "    if (errorState or (not(commentList and 'comments' in commentList))):\n",
    "        if (debug):\n",
    "            print ('Error')\n",
    "        return(False, 0, retError)\n",
    "\n",
    "    comment_df = pd.DataFrame(pd.json_normalize(commentList['comments']))\n",
    "    if (len(comment_df.index) == 0) or ('id' not in comment_df) :\n",
    "        return (False, 0, None)\n",
    "    \n",
    "    commentCount = 0\n",
    "    if 'id' in comment_df:\n",
    "        commentCount = comment_df['id'].nunique()\n",
    "        \n",
    "    resolvedCount = 0\n",
    "    if 'resolved' in comment_df:\n",
    "        resolvedCount = sum(comment_df['resolved'].notna())\n",
    "    \n",
    "    reply_df = pd.DataFrame(pd.json_normalize(commentList['comments'], record_path=['replies']))\n",
    "    resolvedAction = 0\n",
    "    if 'action' in reply_df:\n",
    "        resolvedAction = sum(reply_df['action'] == 'resolve')\n",
    "\n",
    "    totalReplies = 0\n",
    "    if ('id' in reply_df):\n",
    "        totalReplies = reply_df['id'].nunique()\n",
    "    \n",
    "    commenters = []\n",
    "    if 'author.displayName' in reply_df:\n",
    "        commenters = list(reply_df['author.displayName'].unique())\n",
    "    \n",
    "    resultDic = {\"commentCount\": commentCount, \n",
    "                \"resolvedCount\": resolvedCount, # comments that were resolved\n",
    "                \"resolvedActions\" : resolvedAction, #hit resolve on a comment (w/o text/response)\n",
    "                \"totalReplies\" : totalReplies,\n",
    "                \"commenters\" : commenters }\n",
    "    if (debug):\n",
    "        print (resultDic)\n",
    "    return(True, commentCount, resultDic)\n",
    "\n",
    "\n",
    "def getDocumentFromID(docID, creds, debug=False):\n",
    "    service = build('docs', 'v1', credentials=creds)\n",
    "\n",
    "    retError = \"\"\n",
    "    errorState = False\n",
    "    try:\n",
    "        document = service.documents().get(documentId=docID).execute()\n",
    "    except HttpError as ex:\n",
    "        errorState = True\n",
    "        template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "        message = template.format(type(ex).__name__, ex.args)\n",
    "        if (debug):\n",
    "            print (message)\n",
    "        retError = str(ex.resp.status)\n",
    "        if ex.resp.get('content-type', '').startswith('application/json'):\n",
    "            reason = json.loads(ex.content).get('error').get('errors')[0].get('reason')\n",
    "            saveString = json.loads(ex.content)\n",
    "            if (debug):\n",
    "                print (ex.resp.status, reason)\n",
    "            retError = str(ex.resp.status) + ' - ' + reason\n",
    "    \n",
    "    if (errorState or (not(document))):\n",
    "        if (debug):\n",
    "            print ('Error')\n",
    "        return(False, {}, retError)\n",
    "    \n",
    "    return(True, document, retError)\n",
    "\n",
    "def getDocTitleFromID(docID, creds, debug=False):\n",
    "    (res, jsonDoc, errText) = getDocumentFromID(docID, creds, debug)\n",
    "    if (not res):\n",
    "        return (res, jsonDoc, errText)\n",
    "    elif ('title' in jsonDoc) and ('documentId' in jsonDoc):\n",
    "        if (debug):\n",
    "            print ('found title and documentId..')\n",
    "        return(res, jsonDoc['title'], jsonDoc['documentId'])\n",
    "    else:\n",
    "        if (debug):\n",
    "            print ('fail not found')\n",
    "        return(res, '','')\n",
    "\n",
    "def getFileListing(in_df,  searchString, searchTopic, searchTag='ZZZZZZ', debug=False):\n",
    "    if (debug and 'id' in in_df):\n",
    "        print (len(in_df.index), in_df['id'].nunique())\n",
    "\n",
    "    for t in searchTopic:\n",
    "        qString = searchString.replace(searchTag, t)\n",
    "        (res, result_df, errTxt) = searchGDrive(qString, creds, debug=False)\n",
    "        n = 0\n",
    "        if (res) and (len(result_df.index) > 0) :\n",
    "            if 'files' in result_df:\n",
    "                temp_df = pd.DataFrame(pd.json_normalize(result_df['files']).T)\n",
    "                new_df = pd.DataFrame(list(temp_df[0]))\n",
    "                n = len(new_df.index)\n",
    "                if (debug):\n",
    "                    print ('found: '+t+', results = '+str(n))\n",
    "                new_df['searchTerm'] = t\n",
    "                append_df = new_df.copy()\n",
    "                # only put in unique file entries (e.g. a search may find a file multiple times)\n",
    "                #\n",
    "                if ('id' in in_df and 'id' in new_df):\n",
    "                    \n",
    "                    l = ~new_df.id.isin(list(in_df['id'].unique()))\n",
    "                    if (debug) and (sum(l) != len(new_df.index)):\n",
    "                        print('Found Duplicates', sum(l), len(new_df.index))\n",
    "\n",
    "                    append_df = new_df.loc[l,].copy()\n",
    "                    \n",
    "                if (debug):\n",
    "                    print ('appending:', len(append_df.index))\n",
    "                in_df = pd.concat([in_df, append_df], ignore_index=True)\n",
    "    if (debug):\n",
    "        print (len(in_df.index), in_df['id'].nunique())\n",
    "    return(in_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe4af6e",
   "metadata": {},
   "source": [
    "## Query Examples:\n",
    "  * query = \"mimeType='application/vnd.google-apps.document' and trashed=false and name contains 'Kafka'\"\n",
    "  * query = \"modifiedDate > '2021-06-04T12:00:00'\"\n",
    "  * query = \"mimeType='application/vnd.google-apps.document' and trashed=false and name contains 'Kafka' and fullText contains 'scale' and 'user@host.com' in writers\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bceacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = getCreds(SCOPES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d955d1d1",
   "metadata": {},
   "source": [
    "## Search by Topic String in File Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13a1bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "titleStrings = ['design', 'requirements', 'prd', 'spec', 'proposal', 'decision']\n",
    "searchTag = 'ZZZZZZ'\n",
    "query = \"mimeType='application/vnd.google-apps.document' and trashed=false and name contains '\"+searchTag+\"' and fullText contains 'Kafka' and createdTime > '2021-01-01T03:09:26.605Z'\"\n",
    "\n",
    "files_df = pd.DataFrame()\n",
    "files_df = getFileListing(files_df,  query, titleStrings, searchTag, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b890ba0",
   "metadata": {},
   "source": [
    "## Search by PM writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f1b57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmStrings = ['first.last', 'another_user']\n",
    "searchTag = 'ZZZZZZ'\n",
    "query = \"mimeType='application/vnd.google-apps.document' and trashed=false and name contains 'Kafka' and fullText contains 'Interesting' and 'ZZZZZZ@user.com' in writers\"\n",
    "\n",
    "files_df = getFileListing(files_df,  query, pmStrings, searchTag, False)\n",
    "save_files_df = files_df.copy()\n",
    "print (len(save_files_df.index), len(files_df.index), files_df['id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa45829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_files_df['id'].iloc[35:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511bbeda",
   "metadata": {},
   "source": [
    "## Get title, comments and other metadata for the GoogleDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cec2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df['commentCount'] = 0\n",
    "files_df['totalReplies'] = 0\n",
    "files_df['commenters'] = ''\n",
    "files_df['keywords'] = ''\n",
    "files_df['size'] = 0\n",
    "files_df['wordcount'] = 0\n",
    "baseURL = 'https://docs.google.com/document/d/'\n",
    "files_df['url']  = baseURL + files_df['id'] + '/preview'\n",
    "keywordCount = 7\n",
    "debugString = True\n",
    "\n",
    "fileProcessed = 0\n",
    "#for index, row in files_df.iloc[:12].iterrows():\n",
    "for index, row in files_df.iterrows():\n",
    "    (res, commentCount, commentDic) = getCommentInfo(row['id'], creds, debug=False)\n",
    "    if (debugString):\n",
    "        print (fileProcessed, index, 'DocID:', row['id'])\n",
    "    fileProcessed = fileProcessed + 1\n",
    "    if (res and commentCount > 0):\n",
    "        # print (commentDic['commentCount'], commentDic['totalReplies'], commentDic['commenters'])\n",
    "        files_df.at[index,'commentCount'] = commentDic['commentCount']\n",
    "        files_df.at[index,'totalReplies'] = commentDic['totalReplies']\n",
    "        if 'commenters' in commentDic:\n",
    "            #files_df.at[index,'commenters'] = [','.join(map(str, l)) for l in commentDic['commenters']]\n",
    "            # print (', '.join(commentDic['commenters']))\n",
    "            files_df.at[index,'commenters']  = ', '.join(commentDic['commenters'])\n",
    "            \n",
    "    (res, titleStr, idStr) = getDocTitleFromID(row['id'], creds, debug=False)\n",
    "    if (res and len(titleStr) > 0):\n",
    "        files_df.at[index,'title'] = titleStr\n",
    "        \n",
    "    (res, fileText) = googleDriveText(row['id'], creds)\n",
    "\n",
    "    \n",
    "    if (res and len(fileText) > 0):\n",
    "        (kws, summaryText) = getSummary(fileText, keywordCount)\n",
    "        if (len(kws) > 0):\n",
    "            files_df.at[index,'keywords'] = kws\n",
    "        files_df.at[index,'wordcount'] = len(fileText.split())\n",
    "        files_df.at[index,'size'] = len(fileText)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0667263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(fileText.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e552de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (list(files_df.columns))\n",
    "files_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac4f361",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(files_df.columns)\n",
    "if 'mimeType' in cols:\n",
    "    cols.remove('mimeType')\n",
    "if 'kind' in cols:\n",
    "    cols.remove('kind')\n",
    "files_df[cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3d9ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_outfile = 'search_index.csv'\n",
    "files_df[cols].to_csv(csv_outfile, index=False)\n",
    "n=len(files_df.index)\n",
    "print ('wrote: '+ str(n) +  ' lines to ' + csv_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d59b420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e993f153",
   "metadata": {},
   "source": [
    "# Done - ZZZZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18f0a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
