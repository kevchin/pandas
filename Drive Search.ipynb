{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e658a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://developers.google.com/drive/api/v3/ref-search-terms\n",
    "# https://developers.google.com/drive/api/v3/search-files\n",
    "# https://developers.google.com/drive/api/v3/reference/comments/list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344e328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os.path\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from googleapiclient import discovery\n",
    "from googleapiclient.errors import HttpError\n",
    "import json\n",
    "import time\n",
    "from datetime import date\n",
    "from time import sleep\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# NLP libraries for keywords and summaries\n",
    "import re\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "#import heapq\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d407c07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCOPES = ['https://www.googleapis.com/auth/documents.readonly', \n",
    "          'https://www.googleapis.com/auth/documents',\n",
    "          'https://www.googleapis.com/auth/drive.metadata.readonly',\n",
    "          'https://www.googleapis.com/auth/drive',\n",
    "          'https://www.googleapis.com/auth/drive.file',\n",
    "          'https://www.googleapis.com/auth/drive.readonly'\n",
    "         ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0704ddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCreds(scopes):\n",
    "    creds = None\n",
    "    # The file token.json stores the user's access and refresh tokens, and is\n",
    "    # created automatically when the authorization flow completes for the first\n",
    "    # time.\n",
    "    if os.path.exists('token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('token.json', scopes)\n",
    "    # If there are no (valid) credentials available, let the user log in.\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'credentials.json', scopes)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        # Save the credentials for the next run\n",
    "        with open('token.json', 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "    return(creds)\n",
    "\n",
    "def searchGDrive(query, creds, debug=False):\n",
    "    DRIVE = discovery.build('drive', 'v3', credentials=creds)\n",
    "    retError = \"\"\n",
    "    errorState = False\n",
    "    try:\n",
    "        fileList = DRIVE.files().list(q=query,includeTeamDriveItems=True,\n",
    "                                      includeItemsFromAllDrives=True, \n",
    "                                      supportsAllDrives=True,pageSize=1000).execute()\n",
    "    except HttpError as ex:\n",
    "        errorState = True\n",
    "        template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "        message = template.format(type(ex).__name__, ex.args)\n",
    "        if (debug):\n",
    "            print (message)\n",
    "        retError = str(ex.resp.status)\n",
    "        if ex.resp.get('content-type', '').startswith('application/json'):\n",
    "            reason = json.loads(ex.content).get('error').get('errors')[0].get('reason')\n",
    "            saveString = json.loads(ex.content)\n",
    "            if (debug):\n",
    "                print (ex.resp.status, reason)\n",
    "            retError = str(ex.resp.status) + ' - ' + reason\n",
    "    \n",
    "    if (errorState or (not(fileList and 'files' in fileList))):\n",
    "        if (debug):\n",
    "            print ('Error')\n",
    "        return(False, pd.DataFrame(), retError)\n",
    "\n",
    "    files_df = pd.DataFrame(pd.json_normalize(fileList))\n",
    "    fileCount = len(files_df.index)\n",
    "    if (len(files_df.index) == 0):\n",
    "        return (False, files_df, 'Nothing Found')\n",
    "    return (True, files_df, '')\n",
    "\n",
    "def getDocumentFromID(docID, creds, debug=False):\n",
    "    service = build('docs', 'v1', credentials=creds)\n",
    "\n",
    "    retError = \"\"\n",
    "    errorState = False\n",
    "    try:\n",
    "        document = service.documents().get(documentId=docID).execute()\n",
    "    except HttpError as ex:\n",
    "        errorState = True\n",
    "        template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "        message = template.format(type(ex).__name__, ex.args)\n",
    "        if (debug):\n",
    "            print (message)\n",
    "        retError = str(ex.resp.status)\n",
    "        if ex.resp.get('content-type', '').startswith('application/json'):\n",
    "            reason = json.loads(ex.content).get('error').get('errors')[0].get('reason')\n",
    "            saveString = json.loads(ex.content)\n",
    "            if (debug):\n",
    "                print (ex.resp.status, reason)\n",
    "            retError = str(ex.resp.status) + ' - ' + reason\n",
    "    \n",
    "    if (errorState or (not(document))):\n",
    "        if (debug):\n",
    "            print ('Error')\n",
    "        return(False, {}, retError)\n",
    "    \n",
    "    return(True, document, retError)\n",
    "\n",
    "\n",
    "def googleDriveInfo(fileID, creds, debug=False):\n",
    "    DRIVE = discovery.build('drive', 'v3', credentials=creds)\n",
    "\n",
    "    # Drive V3 API:\n",
    "    # https://developers.google.com/drive/api/v3/reference/files/get?apix_params=%7B%22fileId%22%3A%2217CC-CQb4FZyodNbEUN0dxE1flob4cJRf5Sg7rfg7jx8%22%7D\n",
    "    #\n",
    "    #try:\n",
    "    saveString = \"\"\n",
    "    retError = \"\"\n",
    "    errorState = False\n",
    "    try:\n",
    "        cols = 'name,mimeType,owners,createdTime,modifiedTime,shared,permissions'\n",
    "        fileInfo = DRIVE.files().get(fileId=fileID,fields=cols).execute()\n",
    "    except HttpError as ex:\n",
    "        errorState = True\n",
    "        template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "        message = template.format(type(ex).__name__, ex.args)\n",
    "        if (debug):\n",
    "            print (message)\n",
    "        retError = str(ex.resp.status)\n",
    "        if ex.resp.get('content-type', '').startswith('application/json'):\n",
    "            reason = json.loads(ex.content).get('error').get('errors')[0].get('reason')\n",
    "            saveString = json.loads(ex.content)\n",
    "            if (debug):\n",
    "                print (ex.resp.status, reason)\n",
    "            retError = str(ex.resp.status) + ' - ' + reason\n",
    "        \n",
    "    if (errorState or not(fileInfo)):\n",
    "        return(False, retError)\n",
    "    \n",
    "    if (debug):\n",
    "        print (fileInfo)\n",
    "        \n",
    "    return (True, fileInfo)\n",
    "\n",
    "def googleDriveText(fileID, creds, debug=False):\n",
    "    DRIVE = discovery.build('drive', 'v3', credentials=creds)\n",
    "    retError = \"\"\n",
    "    errorState = False\n",
    "    try:\n",
    "        fileText = DRIVE.files().export(fileId=fileID, mimeType='text/plain').execute()\n",
    "    except HttpError as ex:\n",
    "        errorState = True\n",
    "        template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "        message = template.format(type(ex).__name__, ex.args)\n",
    "        if (debug):\n",
    "            print (message)\n",
    "        retError = str(ex.resp.status)\n",
    "        if ex.resp.get('content-type', '').startswith('application/json'):\n",
    "            reason = json.loads(ex.content).get('error').get('errors')[0].get('reason')\n",
    "            saveString = json.loads(ex.content)\n",
    "            if (debug):\n",
    "                print (ex.resp.status, reason)\n",
    "            retError = str(ex.resp.status) + ' - ' + reason\n",
    "    \n",
    "    if errorState:\n",
    "        if (debug):\n",
    "            print ('Error')\n",
    "        return(False, retError)\n",
    "    else:\n",
    "        if (debug):\n",
    "            print (len(fileText.decode('utf-8')))\n",
    "        return(True, fileText.decode('utf-8'))\n",
    "\n",
    "def getSummary(document, keywordCount = 5, debug=False):\n",
    "    # Removing Square Brackets and Extra Spaces\n",
    "    article_text = re.sub(r'\\[[0-9]*\\]', ' ', document)\n",
    "    article_text = re.sub(r'\\s+', ' ', article_text)\n",
    "    # Removing special characters and digits\n",
    "    formatted_article_text = re.sub('[^a-zA-Z]', ' ', article_text )\n",
    "    formatted_article_text = re.sub(r'\\s+', ' ', formatted_article_text)\n",
    "    sentence_list = nltk.sent_tokenize(article_text)\n",
    "    stopwords = list(ENGLISH_STOP_WORDS)\n",
    "    \n",
    "    word_frequencies = {}\n",
    "    for word in nltk.word_tokenize(formatted_article_text):\n",
    "        if word not in stopwords:\n",
    "            if word not in word_frequencies.keys():\n",
    "                word_frequencies[word] = 1\n",
    "            else:\n",
    "                word_frequencies[word] += 1\n",
    "    maximum_frequncy = 0\n",
    "    if len(word_frequencies) > 0:\n",
    "        maximum_frequncy = max(word_frequencies.values())\n",
    "    else:\n",
    "        if (debug):\n",
    "            print ('Error: frequency is invalid')\n",
    "        return('', '')\n",
    "    \n",
    "    for word in word_frequencies.keys():\n",
    "        word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)\n",
    "        sentence_scores = {}\n",
    "    for sent in sentence_list:\n",
    "        for word in nltk.word_tokenize(sent.lower()):\n",
    "            if word in word_frequencies.keys():\n",
    "                if len(sent.split(' ')) < 30:\n",
    "                    if sent not in sentence_scores.keys():\n",
    "                        sentence_scores[sent] = word_frequencies[word]\n",
    "                    else:\n",
    "                        sentence_scores[sent] += word_frequencies[word]\n",
    "                        \n",
    "    wordslist = nltk.word_tokenize(formatted_article_text)\n",
    "    filtered_words = [words for words in wordslist if words.lower() not in stopwords]\n",
    "\n",
    "    fdist = FreqDist(filtered_words)\n",
    "    frequent_words = [[fdist[word], word] for word in set(filtered_words) if len(word) > 2 and fdist[word] >= 2]\n",
    "\n",
    "    #\n",
    "    # Record the frequency count of\n",
    "    #\n",
    "    sorted_word_frequencies = {}\n",
    "    for item in sorted(frequent_words):\n",
    "        sorted_word_frequencies[item[1]] = item[0]\n",
    "    \n",
    "    interestingKeywords = list(sorted_word_frequencies.keys())[-keywordCount:]\n",
    "        \n",
    "    #summary_sentences = heapq.nlargest(3, sentence_scores, key=sentence_scores.get)\n",
    "    #summary = ' '.join(summary_sentences)\n",
    "    return (interestingKeywords, '' )\n",
    "\n",
    "\n",
    "def getCommentInfoLoop(fileID, creds, debug=False):\n",
    "    DRIVE = discovery.build('drive', 'v3', credentials=creds)\n",
    "    retError = \"\"\n",
    "    errorState = False\n",
    "    maxComments = 100\n",
    "    morePages = True\n",
    "    comment_df = pd.DataFrame()\n",
    "    reply_df = pd.DataFrame()\n",
    "    pageToken = ''\n",
    "    while morePages:\n",
    "        try:\n",
    "            if (len(pageToken) > 0):\n",
    "                commentList = DRIVE.comments().list(fileId=fileID, fields='comments,nextPageToken', pageToken=pageToken, pageSize=maxComments).execute()\n",
    "            else:\n",
    "                commentList = DRIVE.comments().list(fileId=fileID, fields='comments,nextPageToken', pageSize=maxComments).execute()\n",
    "        except HttpError as ex:\n",
    "            errorState = True\n",
    "            template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "            message = template.format(type(ex).__name__, ex.args)\n",
    "            if (debug):\n",
    "                print (message)\n",
    "            retError = str(ex.resp.status)\n",
    "            if ex.resp.get('content-type', '').startswith('application/json'):\n",
    "                reason = json.loads(ex.content).get('error').get('errors')[0].get('reason')\n",
    "                saveString = json.loads(ex.content)\n",
    "                if (debug):\n",
    "                    print (ex.resp.status, reason)\n",
    "                retError = str(ex.resp.status) + ' - ' + reason\n",
    "\n",
    "        if (errorState or (not(commentList and 'comments' in commentList))):\n",
    "            if (debug):\n",
    "                print ('Error')\n",
    "            return(False, 0, retError)\n",
    "\n",
    "        if 'nextPageToken' in commentList:\n",
    "            #print (commentList['nextPageToken'])\n",
    "            pageToken = commentList['nextPageToken']\n",
    "            morePages = True\n",
    "        else:\n",
    "            morePages = False\n",
    "\n",
    "        page_df = pd.DataFrame(pd.json_normalize(commentList['comments']))\n",
    "        pageReply_df = pd.DataFrame(pd.json_normalize(commentList['comments'], record_path=['replies']))\n",
    "        if (len(page_df.index) == 0) or ('id' not in page_df) :\n",
    "            return (False, 0, None)\n",
    "        comment_df = pd.concat([comment_df, page_df], axis=0).reset_index(drop=True)\n",
    "        reply_df = pd.concat([reply_df, pageReply_df], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    #if ()\n",
    "    #return(comment_df)\n",
    "    commentCount = 0\n",
    "    if 'id' in comment_df:\n",
    "        commentCount = comment_df['id'].nunique()\n",
    "        \n",
    "    resolvedCount = 0\n",
    "    if 'resolved' in comment_df:\n",
    "        resolvedCount = sum(comment_df['resolved'].notna())\n",
    "    \n",
    "    #reply_df = pd.DataFrame(pd.json_normalize(commentList['comments'], record_path=['replies']))\n",
    "    resolvedAction = 0\n",
    "    if 'action' in reply_df:\n",
    "        resolvedAction = sum(reply_df['action'] == 'resolve')\n",
    "\n",
    "    totalReplies = 0\n",
    "    if ('id' in reply_df):\n",
    "        totalReplies = reply_df['id'].nunique()\n",
    "    \n",
    "    commenters = []\n",
    "    if 'author.displayName' in reply_df:\n",
    "        commenters = list(reply_df['author.displayName'].unique())\n",
    "    \n",
    "    resultDic = {\"commentCount\": commentCount, \n",
    "                \"resolvedCount\": resolvedCount, # comments that were resolved\n",
    "                \"resolvedActions\" : resolvedAction, #hit resolve on a comment (w/o text/response)\n",
    "                \"totalReplies\" : totalReplies,\n",
    "                \"commenters\" : commenters }\n",
    "    if (debug):\n",
    "        print (resultDic)\n",
    "    return(True, commentCount, resultDic)\n",
    "\n",
    "def getCommentInfo(fileID, creds, debug=False):\n",
    "    DRIVE = discovery.build('drive', 'v3', credentials=creds)\n",
    "    retError = \"\"\n",
    "    errorState = False    \n",
    "    maxComments = 100\n",
    "    try:\n",
    "        commentList = DRIVE.comments().list(fileId=fileID, fields='comments', pageSize=maxComments).execute()    \n",
    "    except HttpError as ex:\n",
    "        errorState = True\n",
    "        template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "        message = template.format(type(ex).__name__, ex.args)\n",
    "        if (debug):\n",
    "            print (message)\n",
    "        retError = str(ex.resp.status)\n",
    "        if ex.resp.get('content-type', '').startswith('application/json'):\n",
    "            reason = json.loads(ex.content).get('error').get('errors')[0].get('reason')\n",
    "            saveString = json.loads(ex.content)\n",
    "            if (debug):\n",
    "                print (ex.resp.status, reason)\n",
    "            retError = str(ex.resp.status) + ' - ' + reason\n",
    "    \n",
    "    if (errorState or (not(commentList and 'comments' in commentList))):\n",
    "        if (debug):\n",
    "            print ('Error')\n",
    "        return(False, 0, retError)\n",
    "\n",
    "    comment_df = pd.DataFrame(pd.json_normalize(commentList['comments']))\n",
    "    if (len(comment_df.index) == 0) or ('id' not in comment_df) :\n",
    "        return (False, 0, None)\n",
    "    \n",
    "    commentCount = 0\n",
    "    if 'id' in comment_df:\n",
    "        commentCount = comment_df['id'].nunique()\n",
    "        if (commentCount == maxComments):\n",
    "            if (debug):\n",
    "                print ('TODO: Need to Paginate the Comments')\n",
    "        \n",
    "    resolvedCount = 0\n",
    "    if 'resolved' in comment_df:\n",
    "        resolvedCount = sum(comment_df['resolved'].notna())\n",
    "    \n",
    "    reply_df = pd.DataFrame(pd.json_normalize(commentList['comments'], record_path=['replies']))\n",
    "    resolvedAction = 0\n",
    "    if 'action' in reply_df:\n",
    "        resolvedAction = sum(reply_df['action'] == 'resolve')\n",
    "\n",
    "    totalReplies = 0\n",
    "    if ('id' in reply_df):\n",
    "        totalReplies = reply_df['id'].nunique()\n",
    "    \n",
    "    commenters = []\n",
    "    if 'author.displayName' in reply_df:\n",
    "        commenters = list(reply_df['author.displayName'].unique())\n",
    "    \n",
    "    resultDic = {\"commentCount\": commentCount, \n",
    "                \"resolvedCount\": resolvedCount, # comments that were resolved\n",
    "                \"resolvedActions\" : resolvedAction, #hit resolve on a comment (w/o text/response)\n",
    "                \"totalReplies\" : totalReplies,\n",
    "                \"commenters\" : commenters }\n",
    "    if (debug):\n",
    "        print (resultDic)\n",
    "    return(True, commentCount, resultDic)\n",
    "\n",
    "\n",
    "def getDocumentFromID(docID, creds, debug=False):\n",
    "    service = build('docs', 'v1', credentials=creds)\n",
    "\n",
    "    retError = \"\"\n",
    "    errorState = False\n",
    "    try:\n",
    "        document = service.documents().get(documentId=docID).execute()\n",
    "    except HttpError as ex:\n",
    "        errorState = True\n",
    "        template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "        message = template.format(type(ex).__name__, ex.args)\n",
    "        if (debug):\n",
    "            print (message)\n",
    "        retError = str(ex.resp.status)\n",
    "        if ex.resp.get('content-type', '').startswith('application/json'):\n",
    "            reason = json.loads(ex.content).get('error').get('errors')[0].get('reason')\n",
    "            saveString = json.loads(ex.content)\n",
    "            if (debug):\n",
    "                print (ex.resp.status, reason)\n",
    "            retError = str(ex.resp.status) + ' - ' + reason\n",
    "    \n",
    "    if (errorState or (not(document))):\n",
    "        if (debug):\n",
    "            print ('Error')\n",
    "        return(False, {}, retError)\n",
    "    \n",
    "    return(True, document, retError)\n",
    "\n",
    "def getDocTitleFromID(docID, creds, debug=False):\n",
    "    (res, jsonDoc, errText) = getDocumentFromID(docID, creds, debug)\n",
    "    if (not res):\n",
    "        return (res, jsonDoc, errText)\n",
    "    elif ('title' in jsonDoc) and ('documentId' in jsonDoc):\n",
    "        if (debug):\n",
    "            print ('found title and documentId..')\n",
    "        return(res, jsonDoc['title'], jsonDoc['documentId'])\n",
    "    else:\n",
    "        if (debug):\n",
    "            print ('fail not found')\n",
    "        return(res, '','')\n",
    "\n",
    "def getDocTimesOwnerFromID(driveID, creds, debug=False):\n",
    "    (res, driveInfo) = googleDriveInfo(driveID, creds, debug)\n",
    "    if (not res):\n",
    "        if (debug):\n",
    "            print ('No results found for docTimes')\n",
    "        return (res, driveInfo,'','')\n",
    "    elif ('createdTime' in driveInfo) and ('modifiedTime' in driveInfo):\n",
    "        if (debug):\n",
    "            print ('found times.. ', '# owner:', len(driveInfo['owners']))\n",
    "        ownerEmail = ''\n",
    "        if 'owners' in driveInfo and len(driveInfo['owners']) == 1:\n",
    "            if (debug):\n",
    "                print('emailName:', driveInfo['owners'][0]['emailAddress'])\n",
    "            ownerEmail = driveInfo['owners'][0]['emailAddress']\n",
    "        return(res, driveInfo['createdTime'], driveInfo['modifiedTime'], ownerEmail)\n",
    "    else:\n",
    "        if (debug):\n",
    "            print ('fail times not found, not not get here')\n",
    "        return(res, '','','')\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "def getFileListing(in_df,  searchString, searchTopic, searchTag='ZZZZZZ', debug=False):\n",
    "    if (debug and 'id' in in_df):\n",
    "        print (len(in_df.index), in_df['id'].nunique())\n",
    "\n",
    "    for t in searchTopic:\n",
    "        qString = searchString.replace(searchTag, t)\n",
    "        (res, result_df, errTxt) = searchGDrive(qString, creds, debug=False)\n",
    "        n = 0\n",
    "        if (res) and (len(result_df.index) > 0) :\n",
    "            if 'files' in result_df:\n",
    "                temp_df = pd.DataFrame(pd.json_normalize(result_df['files']).T)\n",
    "                new_df = pd.DataFrame(list(temp_df[0]))\n",
    "                n = len(new_df.index)\n",
    "                if (debug):\n",
    "                    print ('found: '+t+', results = '+str(n))\n",
    "                new_df['searchTerm'] = t\n",
    "                append_df = new_df.copy()\n",
    "                # only put in unique file entries (e.g. a search may find a file multiple times)\n",
    "                #\n",
    "                if ('id' in in_df and 'id' in new_df):\n",
    "                    \n",
    "                    l = ~new_df.id.isin(list(in_df['id'].unique()))\n",
    "                    if (debug) and (sum(l) != len(new_df.index)):\n",
    "                        print('Found Duplicates', sum(l), len(new_df.index))\n",
    "\n",
    "                    append_df = new_df.loc[l,].copy()\n",
    "                    \n",
    "                if (debug):\n",
    "                    print ('appending:', len(append_df.index))\n",
    "                in_df = pd.concat([in_df, append_df], ignore_index=True)\n",
    "    if (debug):\n",
    "        print (len(in_df.index), in_df['id'].nunique())\n",
    "    return(in_df)\n",
    "\n",
    "\n",
    "def getDocumentFieldsFromID(docID, creds, requestFields=\"\", debug=False):\n",
    "    service = build('docs', 'v1', credentials=creds)\n",
    "\n",
    "    retError = \"\"\n",
    "    errorState = False\n",
    "        \n",
    "    try:\n",
    "            if (len(requestFields) > 0):\n",
    "                document = service.documents().get(documentId=docID,fields=requestFields).execute()\n",
    "            else:\n",
    "                document = service.documents().get(documentId=docID).execute()\n",
    "    except HttpError as ex:\n",
    "        errorState = True\n",
    "        template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "        message = template.format(type(ex).__name__, ex.args)\n",
    "        if (debug):\n",
    "            print (message)\n",
    "        retError = str(ex.resp.status)\n",
    "        if ex.resp.get('content-type', '').startswith('application/json'):\n",
    "            reason = json.loads(ex.content).get('error').get('errors')[0].get('reason')\n",
    "            saveString = json.loads(ex.content)\n",
    "            if (debug):\n",
    "                print (ex.resp.status, reason)\n",
    "            retError = str(ex.resp.status) + ' - ' + reason\n",
    "    \n",
    "    if (errorState or (not(document))):\n",
    "        if (debug):\n",
    "            print ('Error')\n",
    "        return(False, {}, retError)\n",
    "    \n",
    "    return(True, document, retError)\n",
    "\n",
    "def getDocumentURLs(docID, creds, substringMatch, requestFields, debug=False):\n",
    "    (res,docStruct, errTxt) = getDocumentFieldsFromID( docID, creds, requestFields,debug)\n",
    "    if not(res):\n",
    "        return(res, docStruct, errTxt)\n",
    "    temp_df = pd.DataFrame(pd.json_normalize(docStruct['body']['content']))\n",
    "    s_df = pd.DataFrame(pd.json_normalize(temp_df['paragraph.elements'].iloc[1:].T))\n",
    "    if (debug):\n",
    "        print (len(temp_df.index))\n",
    "    urlList = []\n",
    "    for s in s_df.columns:\n",
    "\n",
    "        s_df = pd.DataFrame(pd.json_normalize(temp_df['paragraph.elements'].iloc[1:].T))\n",
    "        x_df = pd.DataFrame(list(s_df.loc[s_df[s].notna(),s]))\n",
    "        if 'textRun.textStyle.link.url' in x_df:\n",
    "            for u in x_df.loc[x_df['textRun.textStyle.link.url'].notna(), 'textRun.textStyle.link.url']:\n",
    "                if (substringMatch in u):\n",
    "                    if (debug):\n",
    "                        print (s, u)\n",
    "                    urlList.append(u)\n",
    "                    \n",
    "    return(True, urlList, len(urlList))\n",
    "\n",
    "def getDocOwnerFromID(driveID, creds, debug=False):\n",
    "    (res, driveInfo) = googleDriveInfo(driveID, creds, debug)\n",
    "    if (not res):\n",
    "        return (res, driveInfo)\n",
    "    elif ('owners' in driveInfo):\n",
    "        if (debug):\n",
    "            print ('found owners..')\n",
    "        return(res, driveInfo['owners'])\n",
    "    else:\n",
    "        if (debug):\n",
    "            print ('fail owner not found, should not get here')\n",
    "        return(res, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6e807c",
   "metadata": {},
   "source": [
    "## Query Examples:\n",
    "  * query = \"mimeType='application/vnd.google-apps.document' and trashed=false and name contains 'BUG'\"\n",
    "  * query = \"modifiedDate > '2021-06-04T12:00:00'\"\n",
    "  * query = \"mimeType='application/vnd.google-apps.document' and trashed=false and name contains 'BUG' and fullText contains 'requirements' and createdTime > '2021-06-09T03:09:26.605Z'\"\n",
    "  * query = \"mimeType='application/vnd.google-apps.document' and trashed=false and name contains 'design' and fullText contains 'BUG' and createdTime > '2021-06-09T03:09:26.605Z'\"\n",
    "  * PRD_query = \"mimeType='application/vnd.google-apps.document' and trashed=false and name contains 'PRD' and fullText contains 'BUG' and createdTime > '2021-01-09T03:09:26.605Z'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4cafd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = getCreds(SCOPES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05956611",
   "metadata": {},
   "source": [
    "## Search by Topic String in File Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016ca987",
   "metadata": {},
   "outputs": [],
   "source": [
    "titleStrings = ['design', 'requirements', 'prd', 'spec', 'proposal', 'decision']\n",
    "searchTag = 'ZZZZZZ'\n",
    "query = \"mimeType='application/vnd.google-apps.document' and trashed=false and name contains '\"+searchTag+\"' and fullText contains 'BUG' and createdTime > '2021-01-01T03:09:26.605Z'\"\n",
    "\n",
    "files_df = pd.DataFrame()\n",
    "files_df = getFileListing(files_df,  query, titleStrings, searchTag, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e22769",
   "metadata": {},
   "source": [
    "## Search anything with BUG in the document within 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55e847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "searchString = ['BUG']\n",
    "query = \"mimeType='application/vnd.google-apps.document' and trashed=false and fullText contains 'ZZZZZZ' \"\n",
    "\n",
    "files_df = getFileListing(files_df,  query, searchString, 'ZZZZZZ', False)\n",
    "save_files2_df = files_df.copy()\n",
    "print (len(save_files_df.index), len(files_df.index), files_df['id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634d7fad",
   "metadata": {},
   "source": [
    "## Performance Optimization - Single Call to Drive Constructor and loop for every ID\n",
    "  * Comments\n",
    "  * owners, creation time, modify time\n",
    "  * text of file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2da6a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDriveMeta(fileList, creds, debug=False):\n",
    "    DRIVE = discovery.build('drive', 'v3', credentials=creds)\n",
    "    global lastCount, lastSuccessID\n",
    "    resultDic = {}\n",
    "    for fileID in fileList:\n",
    "        commentResults = metaComment(DRIVE, fileID, debug)\n",
    "        (retVal, fileText) = metaFileContents(DRIVE, fileID, debug)\n",
    "        (kws, summaryText) = getSummary(fileText, 5)\n",
    "        if (not retVal):\n",
    "            print ('error - metaFileContents', fileID, lastCount)\n",
    "        (retVal, createTime, modifiedTime, emailOwner) = metaFileTimes(DRIVE, fileID, debug)\n",
    "        if (not retVal):\n",
    "            print ('error - metaFileTimes', fileID, lastCount)\n",
    "        \n",
    "        if not (fileID in resultDic):\n",
    "            resultDic[fileID] = [commentResults, fileText, kws, createTime, modifiedTime, emailOwner]\n",
    "            lastSuccessID = fileID\n",
    "        lastCount = lastCount + 1\n",
    "    return(resultDic)\n",
    "\n",
    "def metaFileTimes(DriveSpec, fileID, debug=False):\n",
    "    saveString = \"\"\n",
    "    retError = \"\"\n",
    "    errorState = False\n",
    "    try:\n",
    "        cols = 'name,mimeType,owners,createdTime,modifiedTime,shared,permissions'\n",
    "        fileInfo = DriveSpec.files().get(fileId=fileID,fields=cols).execute()\n",
    "    except HttpError as ex:\n",
    "        errorState = True\n",
    "        template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "        message = template.format(type(ex).__name__, ex.args)\n",
    "        if (debug):\n",
    "            print (message)\n",
    "        retError = str(ex.resp.status)\n",
    "        if ex.resp.get('content-type', '').startswith('application/json'):\n",
    "            reason = json.loads(ex.content).get('error').get('errors')[0].get('reason')\n",
    "            saveString = json.loads(ex.content)\n",
    "            if (debug):\n",
    "                print (ex.resp.status, reason)\n",
    "            retError = str(ex.resp.status) + ' - ' + reason\n",
    "        \n",
    "    if (errorState or not(fileInfo)):\n",
    "        #print ('metaFileTime - errorState', retError)\n",
    "        return(False, retError, None, None)\n",
    "    \n",
    "    if (debug):\n",
    "        print (fileInfo)\n",
    "        \n",
    "    if (not('createdTime' in fileInfo)) or (not('modifiedTime' in fileInfo)):\n",
    "        #print ('metaFileTime - missing field')\n",
    "        return(False, retError, None, None)\n",
    "        \n",
    "    \n",
    "    if (debug):\n",
    "        print ('found times.. ', '# owner:', len(fileInfo['owners']))\n",
    "    ownerEmail = ''\n",
    "    if 'owners' in fileInfo and len(fileInfo['owners']) == 1:\n",
    "        if (debug):\n",
    "            print('emailName:', fileInfo['owners'][0]['emailAddress'])\n",
    "        ownerEmail = fileInfo['owners'][0]['emailAddress']\n",
    "    \n",
    "    return(True, fileInfo['createdTime'], fileInfo['modifiedTime'], ownerEmail)\n",
    "  \n",
    "        \n",
    "def metaFileContents(DriveSpec, fileID, debug=False):\n",
    "    retError = \"\"\n",
    "    errorState = False\n",
    "    try:\n",
    "        fileText = DriveSpec.files().export(fileId=fileID, mimeType='text/plain').execute()\n",
    "    except HttpError as ex:\n",
    "        errorState = True\n",
    "        template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "        message = template.format(type(ex).__name__, ex.args)\n",
    "        if (debug):\n",
    "            print (message)\n",
    "        retError = str(ex.resp.status)\n",
    "        if ex.resp.get('content-type', '').startswith('application/json'):\n",
    "            reason = json.loads(ex.content).get('error').get('errors')[0].get('reason')\n",
    "            saveString = json.loads(ex.content)\n",
    "            if (debug):\n",
    "                print (ex.resp.status, reason)\n",
    "            retError = str(ex.resp.status) + ' - ' + reason\n",
    "    \n",
    "    if errorState:\n",
    "        if (debug):\n",
    "            print ('Error')\n",
    "        return(False, retError)\n",
    "    else:\n",
    "        if (debug):\n",
    "            print (len(fileText.decode('utf-8')))\n",
    "        return(True, fileText.decode('utf-8'))\n",
    "    \n",
    "    \n",
    "def metaComment(DriveSpec, fileID, debug=False):\n",
    "    retError = \"\"\n",
    "    errorState = False\n",
    "    maxComments = 100\n",
    "    morePages = True\n",
    "    comment_df = pd.DataFrame()\n",
    "    reply_df = pd.DataFrame()\n",
    "    pageToken = ''\n",
    "    while morePages:\n",
    "        try:\n",
    "            if (len(pageToken) > 0):\n",
    "                commentList = DriveSpec.comments().list(fileId=fileID, fields='comments,nextPageToken', pageToken=pageToken, pageSize=maxComments).execute()\n",
    "            else:\n",
    "                commentList = DriveSpec.comments().list(fileId=fileID, fields='comments,nextPageToken', pageSize=maxComments).execute()\n",
    "        except HttpError as ex:\n",
    "            errorState = True\n",
    "            template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "            message = template.format(type(ex).__name__, ex.args)\n",
    "            if (debug):\n",
    "                print (message)\n",
    "            retError = str(ex.resp.status)\n",
    "            if ex.resp.get('content-type', '').startswith('application/json'):\n",
    "                reason = json.loads(ex.content).get('error').get('errors')[0].get('reason')\n",
    "                saveString = json.loads(ex.content)\n",
    "                if (debug):\n",
    "                    print (ex.resp.status, reason)\n",
    "                retError = str(ex.resp.status) + ' - ' + reason\n",
    "\n",
    "        if (errorState or (not(commentList and 'comments' in commentList))):\n",
    "            if (debug):\n",
    "                print ('Error')\n",
    "            return(False, 0, retError)\n",
    "\n",
    "        if 'nextPageToken' in commentList:\n",
    "            #print (commentList['nextPageToken'])\n",
    "            pageToken = commentList['nextPageToken']\n",
    "            morePages = True\n",
    "        else:\n",
    "            morePages = False\n",
    "\n",
    "        page_df = pd.DataFrame(pd.json_normalize(commentList['comments']))\n",
    "        pageReply_df = pd.DataFrame(pd.json_normalize(commentList['comments'], record_path=['replies']))\n",
    "        if (len(page_df.index) == 0) or ('id' not in page_df) :\n",
    "            return (False, 0, None)\n",
    "        comment_df = pd.concat([comment_df, page_df], axis=0).reset_index(drop=True)\n",
    "        reply_df = pd.concat([reply_df, pageReply_df], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    commentCount = 0\n",
    "    if 'id' in comment_df:\n",
    "        commentCount = comment_df['id'].nunique()\n",
    "        \n",
    "    resolvedCount = 0\n",
    "    if 'resolved' in comment_df:\n",
    "        resolvedCount = sum(comment_df['resolved'].notna())\n",
    "    \n",
    "    resolvedAction = 0\n",
    "    if 'action' in reply_df:\n",
    "        resolvedAction = sum(reply_df['action'] == 'resolve')\n",
    "\n",
    "    totalReplies = 0\n",
    "    if ('id' in reply_df):\n",
    "        totalReplies = reply_df['id'].nunique()\n",
    "    \n",
    "    commenters = []\n",
    "    if 'author.displayName' in reply_df:\n",
    "        commenters = list(reply_df['author.displayName'].unique())\n",
    "    \n",
    "    resultDic = {\"commentCount\": commentCount, \n",
    "                \"resolvedCount\": resolvedCount, # comments that were resolved\n",
    "                \"resolvedActions\" : resolvedAction, #hit resolve on a comment (w/o text/response)\n",
    "                \"totalReplies\" : totalReplies,\n",
    "                \"commenters\" : commenters }\n",
    "    if (debug):\n",
    "        print (resultDic)\n",
    "    return (resultDic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7c358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lastSuccessID ='' # global\n",
    "lastCount = 0     # global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58303431",
   "metadata": {},
   "outputs": [],
   "source": [
    "infoDic = getDriveMeta(files, creds, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1372b9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(files_df.index), files_df['id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0381237",
   "metadata": {},
   "outputs": [],
   "source": [
    "f100 = list(files_df['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c44b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "f100 = list(files_df['id'].unique())\n",
    "print (len(f100))\n",
    "\n",
    "batchSize = 100\n",
    "batches = len(f100)//batchSize +1\n",
    "print (batches)\n",
    "\n",
    "\n",
    "\n",
    "#for i in range(0,5):\n",
    "for j in range(batches):\n",
    "    start = time.time()\n",
    "    print (j,batchSize*j, batchSize*(j+1))\n",
    "    infoDic[j] = getDriveMeta(f100[batchSize*j : batchSize*(j+1)], creds, debug=False)\n",
    "    end = time.time()\n",
    "    print(end - start, lastSuccessID, lastCount, len(infoDic[j]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53afbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict2df(inDict):\n",
    "    for key, values in inDict.items():\n",
    "        if (inDict[key][0]):\n",
    "            print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c754fbad",
   "metadata": {},
   "source": [
    "## Get title, comments and other metadata for the GoogleDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c33063e",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df['commentCount'] = 0\n",
    "files_df['totalReplies'] = 0\n",
    "files_df['commenters'] = ''\n",
    "files_df['keywords'] = ''\n",
    "files_df['created'] = ''\n",
    "files_df['modified'] = ''\n",
    "files_df['owner'] = ''\n",
    "files_df['size'] = 0\n",
    "files_df['wordcount'] = 0\n",
    "files_df['commenterCount'] = 0\n",
    "baseURL = 'https://docs.google.com/document/d/'\n",
    "files_df['url']  = baseURL + files_df['id'] + '/preview'\n",
    "keywordCount = 7\n",
    "debugString = True\n",
    "\n",
    "fileProcessed = 0\n",
    "#for index, row in files_df.iloc[:12].iterrows():\n",
    "for index, row in files_df.iterrows():\n",
    "    (res, commentCount, commentDic) = getCommentInfoLoop(row['id'], creds, debug=False) #DRIVE\n",
    "    if (debugString):\n",
    "        print (fileProcessed,' of ', len(files_df.index), 'index=', index, 'DocID:', row['id'])\n",
    "    fileProcessed = fileProcessed + 1\n",
    "    if (res and commentCount > 0):\n",
    "        # print (commentDic['commentCount'], commentDic['totalReplies'], commentDic['commenters'])\n",
    "        files_df.at[index,'commentCount'] = commentDic['commentCount']\n",
    "        files_df.at[index,'totalReplies'] = commentDic['totalReplies']\n",
    "        if 'commenters' in commentDic:\n",
    "            #files_df.at[index,'commenters'] = [','.join(map(str, l)) for l in commentDic['commenters']]\n",
    "            # print (', '.join(commentDic['commenters']))\n",
    "            files_df.at[index,'commenters']  = ', '.join(commentDic['commenters'])\n",
    "            files_df.at[index,'commenterCount']  = len(commentDic['commenters'])\n",
    "            \n",
    "    (res, titleStr, idStr) = getDocTitleFromID(row['id'], creds, debug=False) #Docs V1\n",
    "    if (res and len(titleStr) > 0):\n",
    "        files_df.at[index,'title'] = titleStr\n",
    "        \n",
    "    (res, fileText) = googleDriveText(row['id'], creds) # DRIVE V3\n",
    "\n",
    "    \n",
    "    if (res and len(fileText) > 0):\n",
    "        (kws, summaryText) = getSummary(fileText, keywordCount)\n",
    "        if (len(kws) > 0):\n",
    "            files_df.at[index,'keywords'] = kws\n",
    "        files_df.at[index,'wordcount'] = len(fileText.split())\n",
    "        files_df.at[index,'size'] = len(fileText)\n",
    "        \n",
    "    (res, created, modified, ownerEmail) = getDocTimesOwnerFromID(row['id'], creds, debug=False) # DRIVE V3\n",
    "    if (res and len(created) > 0):\n",
    "        files_df.at[index,'created'] = created\n",
    "        files_df.at[index,'modified'] = modified\n",
    "    if (res and len(ownerEmail) > 0):\n",
    "        files_df.at[index,'owner'] = ownerEmail\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024a02d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(fileText.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b9b282",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (list(files_df.columns))\n",
    "files_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390600eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(files_df.columns)\n",
    "if 'mimeType' in cols:\n",
    "    cols.remove('mimeType')\n",
    "if 'kind' in cols:\n",
    "    cols.remove('kind')\n",
    "files_df[cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0177a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f72a866",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = cols[-2:] + cols[:-2]\n",
    "cols.append(cols.pop(cols.index('url')))\n",
    "cols.append(cols.pop(cols.index('id')))\n",
    "cols.append(cols.pop(cols.index('teamDriveId')))\n",
    "cols.append(cols.pop(cols.index('driveId')))\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdcedab",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "\n",
    "# dd/mm/YY\n",
    "d1 = today.strftime(\"%d%b%y\")\n",
    "print (d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8b5f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_outfile = 'search_index_long_' + d1 + '.csv'\n",
    "files_df = files_df.sort_values(by='commentCount', ascending=False)\n",
    "files_df[cols].to_csv(csv_outfile, index=False)\n",
    "n=len(files_df.index)\n",
    "print ('wrote: '+ str(n) +  ' lines to ' + csv_outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c46396c",
   "metadata": {},
   "source": [
    "## Read dataframe for owner processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd05ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = 'search_index_long_' + d1 + '.csv'\n",
    "doc_df = pd.read_csv(infile)\n",
    "print (len(doc_df.index))\n",
    "doc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eef0d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d60cb4c0",
   "metadata": {},
   "source": [
    "# Done - ZZZZ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
